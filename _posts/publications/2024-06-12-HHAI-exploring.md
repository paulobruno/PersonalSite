---
title: "Exploring Large Language Models Capabilities to Explain Decision Trees"
subtitle: "Hybrid Human AI Systems for the Social Good (HHAI)"
thumbnail: /assets/images/dt_to_nle.jpg
header:
    teaser: /assets/images/dt_to_nle.jpg
categories:
  - Publication
tags:
  - Explainable AI
  - Large Language Models
  - HHAI
---

*Hybrid Human AI Systems for the Social Good (HHAI)*

[Paulo Bruno de Sousa Serafim](https://paulobruno.github.io)<sup>1</sup>
  [Pierluigi Crescenzi](https://www.pilucrescenzi.it)<sup>1</sup>
  [Gizem Gezici](https://orcid.org/0000-0001-9782-5751#)<sup>2</sup>  
[Eleonora Cappuccio](https://elecapp.github.io/)<sup>3,4</sup>
  [Salvatore Rinzivillo](https://kdd.isti.cnr.it/people/rinzivillo-salvatore)<sup>4</sup>
  [Fosca Giannotti](https://kdd.isti.cnr.it/people/giannotti-fosca)<sup>2</sup>

<p style="font-size:0.7em">
    <sup>1</sup>Gran Sasso Science Institute
     <sup>2</sup>Scuola Normale Superiore di Pisa<br>
    <sup>3</sup>Università di Pisa, Università di Bari Aldo Moro
     <sup>4</sup>Istituto di Scienza e Tecnologie dell’Informazione, CNR<br>
</p>

![DT to NLE Pipeline](/assets/images/dt_to_nle.jpg)

---

Paper: [[PDF](https://ebooks.iospress.nl/volumearticle/68000)]


### Abstract

<p style="text-align:justify;">
Decision trees are widely adopted in Machine Learning tasks due to their operation simplicity and interpretability aspects. However, following the decision process path taken by trees can be difficult in a complex scenario or in a case where a user has no familiarity with them. Prior research showed that converting outcomes to natural language is an accessible way to facilitate understanding for non-expert users in several tasks. More recently, there has been a growing effort to use Large Language Models (LLMs) as a tool for providing natural language texts. In this paper, we examine the proficiency of LLMs to explain decision tree predictions in simple terms through the generation of natural language explanations. By exploring different textual representations and prompt engineering strategies, we identify capabilities that strengthen LLMs as a competent explainer as well as highlight potential challenges and limitations, opening further research possibilities on natural language explanations for decision trees.
</p>


### BibTeX

<p style="text-align:left">
  <a  href="/assets/citations/serafim2024exploring.bib">Download</a>
</p>

```
@inproceedings{serafim2024exploring,
  title = {Exploring Large Language Models Capabilities to Explain Decision Trees},
  author  = {Serafim, Paulo Bruno Sousa and
    Crescenzi, Pierluigi and
    Gezici, Gizem and
    Cappuccio, Eleonora and
    Rinzivillo, Salvatore and
    Giannotti, Fosca},
  booktitle = {Journal of Open Source Software},
  year = {2024},
  series = {Frontiers in Artificial Intelligence and Applications},
  editor = {Lorig, Fabian and
    Tucker, Jason and
    Lindstr{\"o}m,, Adam Dahlgren and
    Dignum, Frank and
    Murukannaiah, Pradeep and
    Theodorou, Andreas and
    Yolum, Pinar},
  volume = {386},
  pages = {64--72},
  doi = {10.3233/FAIA240183}
}
```
